{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq sagemaker docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langchain_community langgraph langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# import dotenv\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"comics\"\n",
    "os.environ[\"api_endpoint\"] =  \"http://127.0.0.1:8080/invocations\"\n",
    "#load env from .env\n",
    "# dotenv.load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Utils functions\n",
    "### 1.1 Structrued Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from json import JSONDecodeError\n",
    "\n",
    "def dict_to_obj(json_str:dict, target:object):\n",
    "    return target.parse_obj(json_str)\n",
    "\n",
    "\n",
    "class CustJsonOuputParser(BaseOutputParser[str]): \n",
    "    verbose :bool = Field( default=True)\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        if self.verbose:\n",
    "            print(text)\n",
    "        pattern = r\"<answer>(.*?)</answer>\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            # print(text)\n",
    "            # text = text.replace('[','(').replace(']',')') ##避免跟sentiment的格式冲突\n",
    "        else:\n",
    "            return {'answer':\"no\"}    \n",
    "        new_dict = json.loads(text.replace('\\n','  '))\n",
    "        \n",
    "        return new_dict\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "class TextOuputParser(BaseOutputParser[str]): \n",
    "    verbose :bool = Field( default=True)\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        if self.verbose:\n",
    "            print(text)\n",
    "        pattern = r\"<answer>(.*?)</answer>\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            return text.strip()\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"TextOuputParser\"\n",
    "    \n",
    "    \n",
    "outparser = CustJsonOuputParser(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_sonnet = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.8,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.9,\n",
    "                                \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                #   callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                )\n",
    "\n",
    "llm_haiku = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.8,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.9,\n",
    "                                \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                  )\n",
    "\n",
    "llm_llama = ChatBedrock(model_id=\"meta.llama3-70b-instruct-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.5,\n",
    "                                \"max_gen_len\": 2048,\n",
    "                                \"top_p\":0.9,\n",
    "                                # \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                  )\n",
    "\n",
    "llm_cr = ChatBedrock(model_id=\"cohere.command-r-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.8,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.5,\n",
    "                                \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                  )\n",
    "\n",
    "llm = llm_haiku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# llm_llama.invoke(\"[USER] hello [USER] \")\n",
    "# llm_cr.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Image Generation model invoke code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bedrock SD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from botocore.exceptions import ClientError\n",
    "from enum import Enum\n",
    "from io import BytesIO\n",
    "\n",
    "# profile='default'\n",
    "profile=''\n",
    "\n",
    "class StyleEnum(Enum):\n",
    "    Photographic = \"photographic\"\n",
    "    Tile_texture = \"tile-texture\"\n",
    "    Digital_art = \"digital-art\"\n",
    "    Origami = \"origami\"\n",
    "    Modeling_compound = \"modeling-compound\"\n",
    "    Anime = \"anime\"\n",
    "    Cinematic = \"cinematic\"\n",
    "    Model_3D = \"3d-model\"\n",
    "    Comicbook = \"comic-book\"\n",
    "    Enhance = \"enhance\"\n",
    "    \n",
    "class ImageError(Exception):\n",
    "    \"Custom exception for errors returned by SDXL\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "class ImageGenerator(BaseModel):\n",
    "    model_id: str = Field(default=\"stability.stable-diffusion-xl-v1\")\n",
    "    profile:str\n",
    "    cfg_scale: int = Field( default=7)\n",
    "    steps:int = Field( default=50)\n",
    "    samples:int = Field( default=1)\n",
    "    \n",
    "    def _generate(self,model_id, body):\n",
    "        \"\"\"\n",
    "        Generate an image using SDXL 1.0 on demand.\n",
    "        Args:\n",
    "            model_id (str): The model ID to use.\n",
    "            body (str) : The request body to use.\n",
    "        Returns:\n",
    "            image_bytes (bytes): The image generated by the model.\n",
    "        \"\"\"\n",
    "\n",
    "        # logger.info(\"Generating image with SDXL model %s\", model_id)\n",
    "\n",
    "        session = boto3.Session()\n",
    "        # session = boto3.Session(profile_name=self.profile)\n",
    "        #get bedrock service \n",
    "        bedrock = session.client(service_name='bedrock-runtime')\n",
    "    \n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        response = bedrock.invoke_model(\n",
    "            body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "        base64_image = response_body.get(\"artifacts\")[0].get(\"base64\")\n",
    "        base64_bytes = base64_image.encode('ascii')\n",
    "        image_bytes = base64.b64decode(base64_bytes)\n",
    "\n",
    "        finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\")\n",
    "\n",
    "        if finish_reason == 'ERROR' or finish_reason == 'CONTENT_FILTERED':\n",
    "            raise ImageError(f\"Image generation error. Error code is {finish_reason}\")\n",
    "\n",
    "\n",
    "        # logger.info(\"Successfully generated image withvthe SDXL 1.0 model %s\", model_id)\n",
    "\n",
    "        return image_bytes\n",
    "\n",
    "    def generate_image( self,prompt,seed=0,style_preset=StyleEnum.Photographic.value):\n",
    "        if self.model_id.startswith('stability'):\n",
    "            body=json.dumps({\n",
    "                \"text_prompts\": [\n",
    "                {\n",
    "                \"text\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"cfg_scale\": self.cfg_scale,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": self.steps,\n",
    "              \"height\": 768,\n",
    "            \"width\": 768,\n",
    "            \"samples\" : self.samples,\n",
    "            \"style_preset\" : style_preset\n",
    "            })\n",
    "        elif self.model_id.startswith('amazon'):\n",
    "            body = json.dumps({\n",
    "            \"taskType\": \"TEXT_IMAGE\",\n",
    "            \"textToImageParams\": {\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"height\": 768,\n",
    "                \"width\": 768,\n",
    "                \"cfgScale\": self.cfg_scale,\n",
    "                \"seed\": seed\n",
    "            }\n",
    "            })\n",
    "        print(body)\n",
    "        image= None\n",
    "        try:\n",
    "            image_bytes=self._generate(model_id = self.model_id,\n",
    "                                    body = body)\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        except ClientError as err:\n",
    "            message=err.response[\"Error\"][\"Message\"]\n",
    "            # logger.error(\"A client error occurred: %s\", message)\n",
    "            print(\"A client error occured: \" +format(message))\n",
    "        except ImageError as err:\n",
    "            print(err)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "        finally:\n",
    "            return image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sagemaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from typing import Any, List\n",
    "import json\n",
    "import io\n",
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "import time\n",
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "\n",
    "def base64_to_image(base64_string):\n",
    "    image_bytes = base64.b64decode(base64_string)\n",
    "    image_buffer = BytesIO(image_bytes)\n",
    "    image = Image.open(image_buffer)\n",
    "    return image\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "\n",
    "class StoryDiffusionGenerator():\n",
    "    \"\"\" API schema\n",
    "    class APIRequest(BaseModel):\n",
    "        sd_type: Literal['RealVision','SDXL','Unstable'] = Field(default='SDXL')\n",
    "        modeltype : Literal[\"Only Using Textual Description\",\"Using Ref Images\"] = Field(default=\"Only Using Textual Description\")\n",
    "        files: Any = Field(default=None)\n",
    "        num_steps : int = Field(default=50)\n",
    "        style : Literal[\"Japanese Anime\",\"(No style)\",\"Cinematic\",\"Disney Charactor\",\"Photographic\",\"Comic book\",\"Line art\"] = Field(default=\"Comic book\")\n",
    "        Ip_Adapter_Strength : float = Field(default=0.5, descrition=\"The strength of the IP adapter. The value ranges from 0 to 1. The larger the value, the stronger the IP adapter.\")\n",
    "        style_strength_ratio : int = Field(default=20 ,descrition=\"Style strength of Ref Image (%)\")\n",
    "        guidance_scale: float = Field(default=5.0)\n",
    "        seed_: int = Field(default=0)\n",
    "        sa32_:float = Field(default=0.5)\n",
    "        sa64_:float = Field(default=0.5)\n",
    "        id_length_ : int = Field(default=2,descrition=\"Number of id images in total images\")\n",
    "        general_prompt : str = Field(...,descrition=\"Textual Description for Character\")\n",
    "        negative_prompt : str =  Field(default=\"naked, deformed, bad anatomy, disfigured, poorly drawn face, mutation, extra limb, ugly, disgusting, poorly drawn hands, missing limb, floating limbs, disconnected limbs, blurry, watermarks, oversaturated, distorted hands, amputation\")\n",
    "        prompt_array: str =  Field(...,descrition=\"Comic Description (each line corresponds to a frame)\")\n",
    "        G_height: int = Field(default=512)\n",
    "        G_width: int = Field(default=512)\n",
    "        comic_type : Literal['No typesetting (default)','Four Pannel','Classic Comic Style'] = Field(default='Classic Comic Style')\n",
    "        font_choice :str = Field(default='Inkfree.ttf')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,endpoint_name,profile):\n",
    "        endpoint_name = endpoint_name\n",
    "        # boto_session= boto3.Session(profile_name=profile)\n",
    "        boto_session= boto3.Session()\n",
    "        self.s3_resource = boto_session.resource(\"s3\")\n",
    "        sagemaker_session = sagemaker.Session(boto_session = boto_session)\n",
    "        bucket  = sagemaker_session.default_bucket()\n",
    "        output_path  = \"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"story-diffusion\")\n",
    "        input_path :str = \"s3://{0}/{1}/asyncinvoke/in/\".format(bucket, \"story-diffusion\")\n",
    "        \n",
    "        predictor_ = Predictor(\n",
    "            endpoint_name=endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            model_data_input_path=input_path,\n",
    "            model_data_output_path=output_path,\n",
    "        )\n",
    "        predictor_.serializer = JSONSerializer()\n",
    "        predictor_.deserializer = JSONDeserializer()\n",
    "        self.config = WaiterConfig(\n",
    "            max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    "        )\n",
    "        self.predictor_async = AsyncPredictor(\n",
    "                predictor_,\n",
    "                name='story-diffusion'\n",
    "        )\n",
    "    \n",
    "    # def get_async_result(self,prediction):\n",
    "    #     images = []\n",
    "    #     try:\n",
    "    #         output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    #         output_obj = self.s3_resource.Object(output_bucket, output_key)\n",
    "    #         body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "            \n",
    "    #         respobj = json.loads(body)\n",
    "    #         print(respobj)\n",
    "    #         for img in respobj['images_base64']:\n",
    "    #             images.append(base64_to_image(img))\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "    #     return images\n",
    "\n",
    "    def generate_images(self,general_prompt:str,prompt_array:str,id_length:int=2, ref_imgs: List[Any]= [],comic_type:str='Classic Comic Style', style:str = 'Japanese Anime',sd_type:str=\"Unstable\", height:int = 512, width :int = 768) -> list:\n",
    "        data = { \"general_prompt\": general_prompt,\n",
    "                        \"prompt_array\" : prompt_array,\n",
    "                        \"style\" : style,\n",
    "                        \"G_height\" : height,\n",
    "                        \"G_width\" : width,\n",
    "                        \"comic_type\" : comic_type,\n",
    "                       \"files\":ref_imgs,\n",
    "                        \"id_length_\":id_length,\n",
    "                        \"sd_type\":sd_type,\n",
    "                }\n",
    "        if not ref_imgs:\n",
    "            del data['files']\n",
    "        # print(data)\n",
    "        prediction = self.predictor_async.predict_async(data)\n",
    "        print(f\"Response output path: {prediction.output_path}\")\n",
    "        start = time.time()\n",
    "        prediction.get_result(self.config)\n",
    "        print(f\"Time taken: {time.time() - start}s\")\n",
    "        \n",
    "        output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "        output_obj = self.s3_resource.Object(output_bucket, output_key)\n",
    "        body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "        \n",
    "        respobj = json.loads(body)\n",
    "        images = []\n",
    "        for img in respobj['images_base64']:\n",
    "            images.append(base64_to_image(img))\n",
    "            \n",
    "        # images =get_async_result(prediction)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate image from model in ec2 server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def generate_images_api(general_prompt:str,prompt_array:str,id_length:int=2, ref_imgs: List[Any]= [],comic_type:str='Classic Comic Style', style:str = 'Japanese Anime',sd_type:str=\"Unstable\",height:int = 768, width :int = 768) -> list:\n",
    "    data = { \"general_prompt\": general_prompt,\n",
    "                    \"prompt_array\" : prompt_array,\n",
    "                    \"style\" : style,\n",
    "                    \"G_height\" : height,\n",
    "                    \"G_width\" : width,\n",
    "                    \"comic_type\" : comic_type,\n",
    "                    \"files\":ref_imgs,\n",
    "                    \"id_length_\":id_length,\n",
    "                    \"sd_type\":sd_type,\n",
    "            }\n",
    "    if not ref_imgs:\n",
    "        del data['files']\n",
    "    payload = json.dumps(data)\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "    url = os.environ['api_endpoint']\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    images = []\n",
    "    for img in response.json()['images_base64']:\n",
    "        images.append(base64_to_image(img))\n",
    "    return images\n",
    "\n",
    "def generate_images_sdxl_api(prompt:str,height:int = 768, width :int = 768,style_preset=StyleEnum.Photographic.value) :\n",
    "    data = { \"prompt\": prompt,\n",
    "            \"G_height\":height,\n",
    "            \"G_width\":width,\n",
    "            \"style_preset\":style_preset}\n",
    "    payload = json.dumps(data)\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "    url = os.environ['api_endpoint']\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    images = []\n",
    "    for img in response.json()['images_base64']:\n",
    "        images.append(base64_to_image(img))\n",
    "    return images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def save_image_file(image, filename, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    image.save(os.path.join(folder, filename))\n",
    "    print(f\"image saved in {os.path.join(folder, filename)}\")\n",
    "    \n",
    "def save_all_images(images,folder='./images'):\n",
    "    img_fnames = []\n",
    "    for i,img in enumerate(images):\n",
    "        fname = str(i)+'.png'\n",
    "        if img:\n",
    "            save_image_file(img,fname,folder)\n",
    "            img_fnames.append(os.path.join(folder, fname))\n",
    "        else:\n",
    "            img_fnames.append(None)\n",
    "    return img_fnames\n",
    "\n",
    "def save_all_images(images:list,file_names:list,folder:str ='./images'):\n",
    "    img_fnames = []\n",
    "    for img,fname in zip(images,file_names):\n",
    "        fname =fname +'.png'\n",
    "        if img:\n",
    "            save_image_file(img,fname,folder)\n",
    "            img_fnames.append(os.path.join(folder, fname))\n",
    "        else:\n",
    "            img_fnames.append(None)\n",
    "    return img_fnames\n",
    "\n",
    "\n",
    "def base64_to_image(base64_string):\n",
    "    image_bytes = base64.b64decode(base64_string)\n",
    "    image_buffer = BytesIO(image_bytes)\n",
    "    image = Image.open(image_buffer)\n",
    "    return image\n",
    "\n",
    "\n",
    "def Image2base64(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    image_data = buffer.getvalue()\n",
    "    base64_encoded_string = base64.b64encode(image_data).decode('utf-8')\n",
    "    return base64_encoded_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "# model_id='amazon.titan-image-generator-v1'\n",
    "\n",
    "model_id='stability.stable-diffusion-xl-v1'\n",
    "image_generator = ImageGenerator(model_id=model_id,profile='')\n",
    "img = image_generator.generate_image(\n",
    "  \"A confident young woman in a stylish tailored suit with bold accessories, standing in a professional setting with an assertive posture and facial expression, photorealistic, sharp focus, studio lighting\"\n",
    ")\n",
    "# img = generate_images_sdxl_api(prompt= \"A confident young woman in a stylish tailored suit with bold accessories, standing in a professional setting with an assertive posture and facial expression, photorealistic, sharp focus, studio lighting\")\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"story-diffusion-inference-api-2024-05-17-14-07-20-411\"\n",
    "sd_image_generator = StoryDiffusionGenerator(endpoint_name=endpoint,profile='')\n",
    "images = sd_image_generator.generate_images(general_prompt = 'a girl',prompt_array=\"wake up in the bed\\nhave breakfast\",height=768,width=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = generate_images_api(general_prompt = 'a girl',prompt_array=\"wake up in the bed\\nhave breakfast\",height=768,width=768,comic_type='No typesetting (default)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[display(img) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Any\n",
    "def get_final_state_env_var(steps:List[Any],node_name:str):\n",
    "    answer = None\n",
    "    for s in steps:\n",
    "        for k in list(s.keys()):\n",
    "            if k == node_name:\n",
    "                answer = s[node_name]['env_var']\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx2pdf import convert\n",
    "def save_image( image, folder='./images') -> str:\n",
    "    \"\"\"Save the image to a temporary file and return the file path.\"\"\"\n",
    "    image_path = f\"temp_{hash(image.tobytes())}.png\"\n",
    "    filename = os.path.join(folder,image_path)\n",
    "    image.save(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def save_as_docx(story, fname):\n",
    "    document = Document()\n",
    "\n",
    "    document.add_heading(story.page_title, 0)\n",
    "\n",
    "    img_idx = 0\n",
    "    for chapter in story.chapters:\n",
    "        document.add_heading(chapter.chapter_title, level=1)\n",
    "        for para in chapter.paragraphs:\n",
    "            print(para)\n",
    "            image = story.images[img_idx]\n",
    "            img_idx += 1\n",
    "            document.add_paragraph(para.content)\n",
    "\n",
    "            # Add the image\n",
    "            if image:\n",
    "                document.add_picture(save_image(image), width=Inches(6))\n",
    "            else:\n",
    "                document.add_picture('placeholder.png', width=Inches(6))\n",
    "\n",
    "    # Save the document\n",
    "    document.save(fname)\n",
    "    print(f'docx file saved as: {fname}')\n",
    "    \n",
    "    # Convert the Word document to PDF\n",
    "    # pdf_path = f\"{fname}.pdf\"\n",
    "    # convert(fname, pdf_path)\n",
    "    # print(f'pdf file saved as: {pdf_path}')\n",
    "\n",
    "\n",
    "\n",
    "def save_as_docx_few(characters,story, fname,suffix=''):\n",
    "    document = Document()\n",
    "\n",
    "    document.add_heading(story.page_title, 0)\n",
    "    document.add_heading('Characters introduction', level=1)\n",
    "    character = characters.main_character\n",
    "    document.add_heading(f\"{character.name}\", level=2)\n",
    "    document.add_paragraph(f\"Role: {character.role}\\nAffiliation: {character.affiliation}\\nBackground: {character.background}\")\n",
    "    document.add_picture(f'./images/{character.name}{suffix}.png', width=Inches(4))\n",
    "    for character in characters.supporting_character:\n",
    "        document.add_heading(f\"{character.name}\", level=2)\n",
    "        document.add_paragraph(f\"Role: {character.role}\\nAffiliation: {character.affiliation}\\nBackground: {character.background}\")\n",
    "        document.add_picture(f'./images/{character.name}{suffix}.png', width=Inches(4))\n",
    "\n",
    "    img_idx = 0\n",
    "    for chapter in story.chapters:\n",
    "        document.add_heading(chapter.chapter_title, level=1)\n",
    "        # Add the image\n",
    "        image = story.images[img_idx]\n",
    "        img_idx += 1\n",
    "        if image:\n",
    "            document.add_picture(save_image(image), width=Inches(6))\n",
    "        else:\n",
    "            document.add_picture('placeholder.png', width=Inches(6))\n",
    "        # Add paragraphs\n",
    "        for para in chapter.paragraphs:\n",
    "            print(para)\n",
    "            document.add_paragraph(para.content)\n",
    "\n",
    "    # Save the document\n",
    "    document.save(fname)\n",
    "    print(f'docx file saved as: {fname}')\n",
    "    \n",
    "    # Convert the Word document to PDF\n",
    "    pdf_path = f\"{fname}.pdf\"\n",
    "    try:\n",
    "        convert(fname, pdf_path)\n",
    "        print(f'pdf file saved as: {pdf_path}')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('pdf file not saved')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Agent Roles settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_setting = \"\"\"You are woking in a cartoon studio, the best and creative cartoon studio in the world.\\n\"\"\"\n",
    "\n",
    "\n",
    "role_config = {\n",
    "\"cartoonist\":  \n",
    "      company_setting+\"\"\"You are a cartoonist.\n",
    "Your task is to write an outline for a comics book about a user-provided topic. Be comprehensive and specific. And keep the outline as long as possible.\n",
    "You can refine your story if there is suggestion provided by other roles in your studio \n",
    "      \"\"\",\n",
    "      \n",
    "\"screenwriter\":  \n",
    "      company_setting+\"\"\"You are a Screenwriter.\n",
    "Your task is to create a main character and a diverse and distinct group of supporting characters for a new story, based on the provided topic and outline.\n",
    "For each supporting character, please provide the following:\n",
    "1. A unique name and role in the story (e.g. sidekick, mentor, rival, etc.)\n",
    "2. A brief description of their perspective, affiliation, or background related to the story's themes\n",
    "3. An explanation of what aspects of the story they will focus on or influence\n",
    "Additionally, think step-by-step about how to make this group of characters distinct and complementary to create an engaging, multifaceted narrative\n",
    "\"\"\",\n",
    "\n",
    "\"editor\": \n",
    "      company_setting+\"\"\"You are a comics book editor, you can proofread and provide suggestions on improving the content of Plot design of the book.\n",
    "Here is outline of a comics book: \n",
    "<outline>\n",
    "{outline}\n",
    "</outline>\n",
    "You are now required to proofread and provide suggestions on specific chapter based on the outline, with the following aspects:\n",
    "<aspects>\n",
    "  1. it should consider the context of other chapters in the outline to continue writing your specific chapter\n",
    "  2. it should consider contradictory plots with other chapter, for example a character who has gone forever in other chapter appearing again in the chapter you are writing\n",
    "  3. it should consider topics such as pornography, racial discrimination, and toxic content\n",
    "  4. it should be compelling and attract young people\n",
    "  4. Any other suggestions which you think can improve the content\n",
    "</aspects>\n",
    "    \"\"\",\n",
    "\"art designer\":\n",
    "\"\"\"You are an art designer. \n",
    "Your task is to generate creative art design ideas and use a Stable Diffusion model to generate high-quality portrait images for the characters in a book,\n",
    "You need to create prompt for Stable Diffusion model with the following instructions:\n",
    "<instructions>\n",
    "1. Consider adding modifiers like aspect ratios, image quality settings, or post-processing instructions to refine the output.\n",
    "2. Avoid topics such as pornography, racial discrimination, and toxic words.\n",
    "3. Be concise and less then 30 words.\n",
    "4. the prompt should always be English\n",
    "5. do not output the character's name, use more general identity instead, such as a young man, an old women, a teenager boy etc.\n",
    "</instructions>\n",
    "Here is example:\n",
    "<example>\n",
    "Prompt: A highly detailed, photorealistic portrait of a young woman with long, curly red hair, fair skin, and piercing green eyes, standing in front of a window overlooking a lush forest, soft natural lighting, 4k, artstation, unreal engine\n",
    "</example>\n",
    "\"\"\",\n",
    "\n",
    "\"story illustrator\":\n",
    "      company_setting+ \"\"\"You are a story illustrator. \n",
    "You first identify the referential relationship in the description and replace the pronouns with the names of the characters, and output your the result in <intermediate_step> tag.\n",
    "Then You need to break down the description in <intermediate_step> into several short sentences with subject-predicate-object relationships, maintaining a certain logical order between the short sentences.\n",
    "put your final answer in xml tag <answer>\n",
    "You need to follow instructions:\n",
    "<instructions>\n",
    "1. Use descriptive keywords or short sentences to convey the desired content, style, action.\n",
    "2. Avoid topics such as pornography, racial discrimination, and toxic words.\n",
    "3. Each sentence should be concise and less then 10 words.\n",
    "4. the output should always be English.\n",
    "5. each sentence in one line\n",
    "6. no more then 8 sentences in total\n",
    "7. If thera are characters name exists in the short sentence,  add brackets to enclose the name. for example, [Bob] invited [Alice] to join him on an adventure\n",
    "8. If there are no characters in the short sentence, add a [NC] symbol at the beginning of the sentence.For example, to generate a scene of falling leaves without any character, write: [NC] The leaves are falling.\n",
    "</instructions>\n",
    "Here is example:\n",
    "<example>\n",
    "input:Bob was at home, reading the newspaper. An article caught his eye – it mentioned a treasure house hidden deep in the forest. Intrigued, Bob decided to embark on an adventure to find this elusive treasure.\n",
    "On the road, near the forest, Bob invited his friend Alice to join him on this exciting quest. Alice, always up for an adventure, eagerly agreed.\n",
    "They drove to the forest, their car winding through the narrow roads, as they ventured deeper into the unknown. As night fell, the forest took on an eerie atmosphere. Suddenly, a tiger appeared, its piercing eyes glowing in the darkness.\n",
    "Bob and Alice were terrified, their mouths agape in fear. Without hesitating, they ran as fast as they could, their hearts pounding in their chests.\n",
    "output:\n",
    "<answer>\n",
    "[Bob] at home, read new paper #at home, The newspaper says there is a treasure house in the forest\n",
    "[Bob] on the road, near the forest\n",
    "[Alice] is make a call at home # [Bob] invited [Alice] to join him on an adventure.\n",
    "[NC] The car on the road, near the forest #They drives to the forest in search of treasure.\n",
    "[NC]A tiger appeared in the forest, at night \n",
    "[Bob] very frightened, open mouth, in the forest, at night\n",
    "[Alice] very frightened, open mouth, in the forest, at night\n",
    "[Bob]  running very fast, in the forest, at night\n",
    "</answer>\n",
    "</example>\n",
    "\"\"\",\n",
    "\n",
    "\n",
    "\"translator\":\n",
    "      company_setting+\"\"\"You are the world's most professional translator, proficient in professional translation between {source_lang} and {dist_lang}. \n",
    "We are testing your output and translation capabilities. You need to follow below instructions: \n",
    "- Translation style: concise, easy to understand, similar to the style of orignal content. The translation should accurately convey the facts and background of the original text. \n",
    "- Avoid quotation mark within a quotation mark, if encountering a quotation mark within a quotation mark, it needs to be single quotation mark instead\n",
    "Do not try to explain the content to be translated, your task is only to translate. \"\"\",\n",
    "\n",
    "\"summarizer\":\n",
    "\"\"\"You are an expert paragraph summarizer. Your task is to summarize a given paragraph into a concise, short sentence while capturing the main idea or key point of the paragraph.\n",
    "Skip the premble, output the summary directly.\n",
    "\"\"\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- structured output prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_desc = \"\"\"\n",
    "You will ALWAYS follow the below guidelines when you are answering a question:\n",
    "<guidelines>\n",
    "- Think through the user's question, extract all data from the question and the previous conversations before creating a plan.\n",
    "- Always output your thoughts within <thinking></thinking> xml tags before you respond to the user. \n",
    "- Your response must be follow the pydantic schema as:\n",
    "<schema>\n",
    "{schema}\n",
    "</shema>\n",
    "- output your answer in json format, enclosed in tag <answer>, so that the user can use pydantic basemodel.parse_obj() to parse the json string into an object which defined as:\n",
    " <schema>\n",
    " {schema}\n",
    " </shema>\n",
    "- Avoid quotation mark within a quotation mark, if encountering a quotation mark within a quotation mark, it needs to be single quotation mark instead\n",
    "- if the content has quotation mark, please change to single quotation mark instead\n",
    "</guidelines>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow_1: Generate Outline Workflow\n",
    "\n",
    "### 2.1 generate initial outline\n",
    "\n",
    "For many topics, your LLM may have an initial idea of the important and related topics. We can generate an initial\n",
    "outline to be refined after our research. Below, we will use our \"fast\" llm to generate the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "\n",
    "class Chapter(BaseModel):\n",
    "    chapter_title: str = Field(..., title=\"Title of the chapter\")\n",
    "    description: str = Field(..., title=\"Summary description of the chapter\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        # chapter_content = \"\\n\".join(self.paragrahs)\n",
    "        return f\"## {self.chapter_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the comics book\")\n",
    "    chapters: List[Chapter] = Field(\n",
    "        default_factory=list,\n",
    "        min_items=8,\n",
    "        # max_items=20,\n",
    "        title=\"Titles and descriptions for each chapter of the comics book.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        chapter = \"\\n\\n\".join(chapter.as_str for chapter in self.chapters)\n",
    "        return f\"# {self.page_title}\\n\\n{chapter}\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prompt template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            role_config[\"cartoonist\"]+ fc_desc,\n",
    "        ),\n",
    "        # (\"user\",  \"Write an outline for a comics book about a user-provided topic. Be comprehensive and specific. And keep the outline as long as possible Here is {topic}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"A little boy who lived in a mountain village obtained a magic book in the wild. He became self-taught and became the most powerful magician in the world, helping the world resist alien invasions. \"\n",
    "# topic = \"续写一位霸道女总裁的故事。她从外交学院毕业之后，经过多年奋斗，终于进入了一家知名企业当副总裁，然而她对下属员工非常刻薄，她在个人抖音账号上发布了多条视频，包括“员工闹分手提离职我秒批”、“300封举报信撒满工位”等话题，这些视频内容引发了公众的热议和争议，终于被公司辞退。被公司辞退前她自己注册了一家公司。\"\n",
    "generate_outline_direct = direct_gen_outline_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) | RunnableLambda(dict_to_obj).bind(target=Outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test for generation\n",
    "- If you encounter JSONDecodeError, please rerun again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = generate_outline_direct.invoke({\"messages\": [HumanMessage(content=f\"Here is the topic:{topic}\")],\"schema\":Outline.schema_json() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Persona(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the character.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"only first name of character, need to match with '^[a-zA-Z0-9_-]{1,64}$'\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the character in the story.\",\n",
    "    )\n",
    "    background: str = Field(\n",
    "        description=\"background of the person in the story.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"description of the character’s personality, hobbies, etc.\",\n",
    "    )\n",
    "    figure: str = Field(\n",
    "        description=\"figure representing such as a boy,a girl,a man, a women, a young woman,an old man or etc\",\n",
    "    )\n",
    "    appearance: str = Field(\n",
    "        description=\"appearance, attire of the character in the story.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nBackground: {self.background}\\nDescription: {self.description}\\nFigure:{self.figure}\\nAppearance: {self.appearance}\\n\"\n",
    "    \n",
    "class Character(BaseModel):\n",
    "    main_character: Persona = Field(\n",
    "        description=\"the main character in the story.\",\n",
    "    )\n",
    "    \n",
    "    supporting_character: List[Persona] = Field(\n",
    "        description=\"Comprehensive list of supporting characters in the story.\",\n",
    "        min_items=2,\n",
    "        max_items=4,\n",
    "    )\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return \"\\n\".join([e.persona for e in self.supporting_character])+'\\n'+self.main_character.persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_character_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "           role_config[\"screenwriter\"]+ fc_desc,\n",
    "        ),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "gen_characters_chain = gen_character_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=Character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = HumanMessage(content=f\"Here is the outline:{outline.as_str}\")\n",
    "characters = gen_characters_chain.invoke({\"messages\": [request],\"schema\":Character.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(characters.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Add charaters to refine outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  test for refine generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = generate_outline_direct.invoke({\"messages\": [HumanMessage(content=f\"Here is the topic:{topic}\"),\n",
    "                                                               AIMessage(content=f\"Here is the outline draft:{outline.json()}, \"),\n",
    "                                                               HumanMessage(content=f\"Here is the characters description:{characters.json()}.\\n Your task is to rewrite the outline draft for a comics book based on the outline draft. Please incorporate all the characters in the story, and keep the outline Be comprehensive and specific \")],\n",
    "                                          \"schema\":Outline.schema_json() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 build outline workflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence,Dict,Optional,Any,TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    env_var: Optional[Annotated[Dict[str, Any], operator.ior]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_message_name(message:BaseMessage):\n",
    "    if isinstance(message, AIMessage) and message.name:\n",
    "        return AIMessage(content=f\"{message.name} : {message.content}\")\n",
    "    elif isinstance(message, HumanMessage) and message.name:\n",
    "        return HumanMessage(content=f\"{message.name} : {message.content}\")\n",
    "    else:\n",
    "        return message\n",
    "\n",
    "##merge the continouse roles, and change sequences \n",
    "def reconstruct_to_claude_messages(messages):\n",
    "    rec_messages = []\n",
    "    for message in messages:\n",
    "        message = convert_message_name(message)\n",
    "        if rec_messages:\n",
    "            if isinstance(rec_messages[0], AIMessage):\n",
    "                rec_messages[0] = HumanMessage(content=rec_messages[0].content)\n",
    "            last_msg = rec_messages[-1]\n",
    "            last_role = 'assistant' if isinstance(last_msg,AIMessage) else 'user'\n",
    "            current_role = 'assistant' if isinstance(message,AIMessage) else 'user'\n",
    "            if last_role == current_role:\n",
    "                last_msg_content = last_msg.content[-1]['text'] if isinstance(last_msg.content,list) else last_msg.content\n",
    "                current_msg_content = message.content[-1]['text'] if isinstance(message.content, list) else message.content\n",
    "                new_content = last_msg_content +\"\\n\\n\" + current_msg_content\n",
    "                rec_messages[-1] = HumanMessage(content=new_content) if last_role == 'user' else AIMessage(content=new_content)\n",
    "            else:\n",
    "                rec_messages.append(message)\n",
    "        else:\n",
    "            rec_messages.append(message)\n",
    "    return rec_messages\n",
    "\n",
    "def swap_roles(messages, name: str):\n",
    "    converted = []\n",
    "    for message in messages:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    return  converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.pydantic_v1 import ValidationError\n",
    "\n",
    "async def retry_call(chain,args: Dict[str,Any],times:int=5):\n",
    "    try:\n",
    "        content = await chain.ainvoke(args)\n",
    "        return content\n",
    "    except JSONDecodeError as e:\n",
    "        if times:\n",
    "            print(f'JSONDecodeError, retry again [{times}]')\n",
    "            return await retry_call(chain,args,times=times-1)\n",
    "        else:\n",
    "            raise(JSONDecodeError(msg='JSONDecodeError'))\n",
    "    except ValidationError as e:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_outline(state:AgentState):\n",
    "    \"\"\"\n",
    "    Generate outline\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with outline\n",
    "    \"\"\"\n",
    "    print(\"---generate_outline---\")\n",
    "    env_var =  state.get(\"env_var\")\n",
    "    assert not env_var is None\n",
    "    \n",
    "    generate_outline_chain = direct_gen_outline_prompt | llm | CustJsonOuputParser(verbose=True) | RunnableLambda(dict_to_obj).bind(target=Outline)\n",
    "    name = \"cartoonist\"\n",
    "    messages = swap_roles(state['messages'],name)\n",
    "    messages = reconstruct_to_claude_messages(messages)\n",
    "    outline = await retry_call(generate_outline_chain,{\"messages\": messages,\"schema\":Outline.schema_json() })\n",
    "    response = AIMessage(content=f\"Here is the outline: \\n{outline.json()}\",name=name)\n",
    "    return {\"messages\":[response],\"env_var\":{**env_var,\"outline\":outline}}\n",
    "\n",
    "async def generate_characters(state:AgentState):\n",
    "    \"\"\"\n",
    "    Generate characters\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with outline\n",
    "    \"\"\"\n",
    "    print(\"---generate_characters---\")\n",
    "    env_var =  state.get(\"env_var\")\n",
    "    assert not env_var is None\n",
    "    \n",
    "    name = 'screenwriter'\n",
    "    messages = swap_roles(state['messages'],name)\n",
    "    messages = reconstruct_to_claude_messages(state['messages'])\n",
    "    gen_characters_chain = gen_character_prompt | llm | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=Character)\n",
    "    characters = await retry_call(gen_characters_chain,{\"messages\": messages,\"schema\":Character.schema_json() })\n",
    "    response = AIMessage(content=f\"Here is the characters description:\\n{characters.json()}.\\n Your task is to rewrite the outline draft for a story based on the outline draft. Please incorporate all the characters in the story, and keep the outline be comprehensive and specific \",name=name)\n",
    "\n",
    "    return {\"messages\":[response],\"env_var\":{**env_var,\"characters\":characters}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TURNS = 2\n",
    "def should_repeat_outline(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    # print(messages)\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage)]\n",
    "    )\n",
    "    print('messages:',num_responses)\n",
    "    if num_responses > MAX_TURNS:\n",
    "        return 'end'\n",
    "    else:\n",
    "        return 'generate_characters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_graph = StateGraph(AgentState)\n",
    "outline_graph.add_node(\"generate_outline\",generate_outline)\n",
    "outline_graph.add_node(\"generate_characters\",generate_characters)\n",
    "outline_graph.set_entry_point(\"generate_outline\")\n",
    "outline_graph.add_edge(\"generate_characters\", \"generate_outline\")\n",
    "outline_graph.add_conditional_edges(\"generate_outline\",\n",
    "                                   should_repeat_outline,\n",
    "                                   {\n",
    "                                       'end':END,\n",
    "                                       'generate_characters':'generate_characters'\n",
    "                                   }\n",
    "                                   )\n",
    "outline_workflow = outline_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(outline_workflow.get_graph().draw_png())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test generation\n",
    "- Sometimes there is exception JSONDecodeError, you should rerun the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "init_state = {\n",
    "    \"env_var\":{\"topic\":topic},\n",
    "    \"messages\":[HumanMessage(content=f\"Here is the topic:{topic}\")]\n",
    "}\n",
    "async for event in outline_workflow.astream(init_state):\n",
    "    print(event)\n",
    "    # print(list(event.values())[0]['env'])\n",
    "    print(\"---\")\n",
    "    steps.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var =  steps[-1]['generate_outline']['env_var']\n",
    "outline = env_var['outline']\n",
    "characters = env_var['characters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(characters.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflow_2 - write story sections in paraller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 define the output structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paragragh(BaseModel):\n",
    "    content: str = Field(..., title=\"Content of the Paragrah\")\n",
    "\n",
    "class DetailChapter(BaseModel):\n",
    "    chapter_title: str = Field(..., title=\"Title of the chapter\")\n",
    "    paragraphs: List[Paragragh] = Field(..., title=\"List of paragraghs of the chapter\")\n",
    "    \n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        chapter_content = \"\\n\".join([p.content for p in self.paragraphs])\n",
    "        return f\"## {self.chapter_title}\\n\\n{chapter_content}\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_chapter_prompt = ChatPromptTemplate.from_messages( \n",
    " [    \n",
    "   (\n",
    "        \"system\",\n",
    "        role_config[\"cartoonist\"]  + \n",
    "         \"\"\"Here is the outline of the story: \n",
    "      <outline>\n",
    "      {outline}\n",
    "      </outline>\n",
    "      Here is the characters of the story:\n",
    "      <characters>\n",
    "      {characters}\n",
    "      </characters>\n",
    "      You are now required to write stories for specific chapter based on the outline and characters, with the following requirements:\n",
    "      <requirements>\n",
    "        1. You need to consider the context of other chapters in the outline to continue writing your specific chapter\n",
    "        2. You can only use the characters to write the story, don't create any other characters beyond the provided characters.\n",
    "        3. Avoid contradictory plots with other chapter, for example a character who has gone forever in other chapter appearing again in the chapter you are writing\n",
    "        4. Avoid topics such as pornography, racial discrimination, and toxic content\n",
    "      </requirements>\"\"\" + fc_desc\n",
    "        ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\", optional=True),  \n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline.chapters[0].json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_chapter_chain = write_chapter_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=DetailChapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_obj = await gen_chapter_chain.ainvoke({\"outline\":outline,\"messages\":[HumanMessage(content = outline.chapters[0].json())],\"characters\":characters.as_str,\"schema\":DetailChapter.schema_json()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter_obj.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Editor to refine the chatper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditorSuggestion(BaseModel):\n",
    "  suggestions: List[str] = Field(\n",
    "      description=\"suggestion list\",\n",
    "      max_items=10,\n",
    "  )\n",
    "  @property\n",
    "  def as_str(self) -> str:\n",
    "      return \"\\n\".join([f\"{i+1}.{e}\" for i,e in enumerate(self.suggestions)])\n",
    "\n",
    "refine_chapter_prompt = ChatPromptTemplate.from_messages( \n",
    " [    \n",
    "   (\n",
    "        \"system\",\n",
    "        role_config[\"editor\"],\n",
    "        ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\", optional=True),  \n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chapter_chain = refine_chapter_prompt | llm_sonnet | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_suggestions = refine_chapter_chain.invoke({\"outline\":outline.json(),\"messages\":[HumanMessage(content=chapter_obj.json())]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refine_suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Build workflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def write_chapter(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    name = 'cartoonist'\n",
    "    messages = swap_roles(messages,name)\n",
    "    # print(messages)\n",
    "    env_var = state['env_var']\n",
    "    outline = env_var['outline']\n",
    "    characters = env_var['characters']\n",
    "    assert not outline == None\n",
    "    messages = reconstruct_to_claude_messages(messages)\n",
    "    assert not outline == None\n",
    "    gen_chapter_chain = write_chapter_prompt | llm | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=DetailChapter)\n",
    "    chapter_obj= await retry_call(gen_chapter_chain,{\"outline\":outline.json(),\"messages\":messages,\"characters\":characters.as_str,\"schema\":DetailChapter.schema_json()})\n",
    "    \n",
    "    \n",
    "    ## sometimes the agent would end the converastion, so it would not follow the structured output. we should end converastion then\n",
    "    if isinstance(chapter_obj,DetailChapter):\n",
    "        formatted_message = AIMessage(name=name, content=chapter_obj.json())\n",
    "        return {\"messages\":[formatted_message],\"env_var\":{**env_var,\"chapter\":chapter_obj}}\n",
    "    else:\n",
    "        return {\"messages\":[AIMessage(name=name, content=\"Let's end the coversation\")],\"env_var\":{**env_var}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def refine_chapter(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    name = \"editor\"\n",
    "    messages = swap_roles(messages,name)\n",
    "    # print(messages)\n",
    "    env_var = state['env_var']\n",
    "    outline = env_var['outline']\n",
    "    assert not outline == None\n",
    "    messages = reconstruct_to_claude_messages(messages)\n",
    "    refine_chapter_chain = refine_chapter_prompt | llm | StrOutputParser()\n",
    "    # suggestion = await refine_chapter_chain.ainvoke({\"outline\":outline,\"messages\":messages})\n",
    "    suggestion = await retry_call(refine_chapter_chain,{\"outline\":outline.json(),\"messages\":messages})\n",
    "    formatted_message = AIMessage(name=name, content=suggestion)\n",
    "    return {\"messages\":[formatted_message],\"env_var\":{**env_var}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TURNS = 2\n",
    "def should_repeat_write(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    last_msg = messages[-1].content\n",
    "    # print(messages)\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage)]\n",
    "    )\n",
    "    print(f'num_responses:{num_responses}')\n",
    "    if num_responses > MAX_TURNS or last_msg.startswith(\"Let's end the coversation\"):\n",
    "        return 'end'\n",
    "    else:\n",
    "        return 'refine_chapter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_graph = StateGraph(AgentState)\n",
    "\n",
    "write_graph.add_node(\"write_chapter\",write_chapter)\n",
    "write_graph.add_node(\"refine_chapter\",refine_chapter)\n",
    "write_graph.set_entry_point(\"write_chapter\")\n",
    "\n",
    "write_graph.add_edge(\"refine_chapter\",\"write_chapter\")\n",
    "write_graph.add_conditional_edges(\"write_chapter\",\n",
    "                                  should_repeat_write,\n",
    "                                  {\n",
    "                                      \"end\":END,\n",
    "                                      \"refine_chapter\":\"refine_chapter\"\n",
    "                                  })\n",
    "write_workflow = write_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(write_workflow.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's test, write a single chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps = []\n",
    "init_state = {\n",
    "    \"env_var\":{\"outline\":outline,\"characters\":characters},\n",
    "    \"messages\":[HumanMessage(content=f\"Here is the origin content: {outline.chapters[0].json()}\",name='editor')]\n",
    "}\n",
    "async for event in write_workflow.astream(input=init_state):\n",
    "    steps.append(event)\n",
    "    for key, value in event.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_final_state_env_var(steps,'write_chapter')['chapter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's use batch function to write each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaps = [ chatper for chatper in  outline.chapters]\n",
    "chaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_all_chapters(chaps,outline,characters):\n",
    "    init_state = {\n",
    "    \"env_var\":{\"outline\":outline,\"characters\":characters,\"chapter\":None},\n",
    "    \"messages\":[HumanMessage(content=f\"Here is the origin content:\\n {chaps.json()}\",name='editor')]\n",
    "    }       \n",
    "    steps = []\n",
    "    async for event in write_workflow.astream(input=init_state):\n",
    "        steps.append(event)\n",
    "        for key, value in event.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            print(value)\n",
    "        print(\"\\n---\\n\")\n",
    "    ret = get_final_state_env_var(steps,'write_chapter')['chapter']\n",
    "    # trans =  get_final_state_env_var(steps,'translate_chapter')['translation']\n",
    "    return (ret,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_all = RunnableLambda(write_all_chapters).bind(outline=outline,characters=characters)\n",
    "all_steps =  await write_all.abatch(chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge all Subchapters together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Story(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the comics book\")\n",
    "    chapters: List[DetailChapter] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each chapter of the comics book.\",\n",
    "    )\n",
    "    images: Optional[List[Any]] = Field(default=[], title=\"List of illustration for each chapter\")\n",
    "    \n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        chapter = \"\\n\\n\".join(chapter.as_str for chapter in self.chapters)\n",
    "        return f\"# {self.page_title}\\n\\n{chapter}\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(outline.as_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "story = Story(page_title=outline.page_title,chapters=[s[0] for s in all_steps])\n",
    "print(len(story.as_str))\n",
    "print(story.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Workflow_4 - Art design -generate Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 setup prompt optimzer for SDXL and StoryDiffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePrompt(BaseModel):\n",
    "    prompt: str = Field(\n",
    "        description=\"an optimized prompt for the Stable Diffusion model based on the given instructions and guidelines, it should always be English\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Firstly generate character identity images using sdxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_identity_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            role_config['art designer']+fc_desc,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\",optional=True),  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_identity_chain = gen_identity_prompt | llm_sonnet | CustJsonOuputParser(verbose=False) |RunnableLambda(dict_to_obj).bind(target=ImagePrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_prompt = gen_identity_chain.invoke({'messages':[HumanMessage(content=characters.main_character.appearance)],'schema':ImagePrompt.schema_json()})\n",
    "sd_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_generator = ImageGenerator(profile='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate all identity images and saved to later story diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_all_identities(characters,gen_identity_chain):\n",
    "    batch_inputs  = [{'messages':[HumanMessage(content=characters.main_character.appearance)],'schema':ImagePrompt.schema_json()}]\n",
    "    character_names = [characters.main_character.name]\n",
    "    for ch in characters.supporting_character:\n",
    "        batch_inputs += [{'messages':[HumanMessage(content=ch.appearance)],'schema':ImagePrompt.schema_json()}]\n",
    "        character_names += [ch.name]\n",
    "    \n",
    "    sd_prompts = gen_identity_chain.batch(batch_inputs)\n",
    "    \n",
    "    image_generator = ImageGenerator(profile='')\n",
    "    images = [image_generator.generate_image(prompt=sd_prompt.prompt) for sd_prompt in sd_prompts]\n",
    "    \n",
    "    # save images in folder\n",
    "    save_all_images(images,character_names)\n",
    "    return images,sd_prompts\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,sd_prompts = generate_all_identities(characters,gen_identity_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generate storylines for story diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StoryLines(BaseModel):\n",
    "#     sentences : List[str] = Field (description=\"\"\"break down a description into several short sentences with subject verb object relationships, maintaining a certain logical order between the sentences. \n",
    "#                                    If there are no characters in the short sentence, add a [NC] symbol at the beginning of the sentence.\n",
    "#                                    For example, to generate a scene of falling leaves without any character, write: [NC] The leaves are falling.\"\"\", \n",
    "#                                    max_items=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            role_config['story illustrator']\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\",optional=True),  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This chain has to be Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_image_prompt_chain =  gen_image_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=StoryLines)\n",
    "gen_image_prompt_chain =  gen_image_prompt | llm_sonnet | TextOuputParser(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = HumanMessage(content='\\n'.join([ p.content for p in story.chapters[0].paragraphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = HumanMessage(content=story.chapters[0].paragraphs[2].content)\n",
    "request = HumanMessage(content='\\n'.join([ p.content for p in story.chapters[0].paragraphs]))\n",
    "gen_image_prompt_chain.invoke({\"messages\":[request]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate story lines for story diffusion in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create image by each paragraph cost very long time, so we only create by chapter instead\n",
    "# messages = [{\"messages\":[HumanMessage(content=f\"Here is the description:\\n{para.content}\")]} for chapter in story.chapters for para in chapter.paragraphs] \n",
    "messages = []\n",
    "for chapter in story.chapters:\n",
    "    messages += [{\"messages\":[HumanMessage(content='\\n'.join([ p.content for p in chapter.paragraphs]))]}] \n",
    "# messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_story_lines = gen_image_prompt_chain.batch(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_story_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = r\"\\[(.*?)\\]\"\n",
    "# story_lines_split = []\n",
    "# for p in all_story_lines:\n",
    "#     match = re.findall(pattern, p)\n",
    "#     match_set = set(match)\n",
    "#     match_set.discard('NC')\n",
    "#     if len(list(match_set)) <= 2:\n",
    "#         story_lines_split.append(p)\n",
    "#     else:\n",
    "#         # print('------------')\n",
    "#         # print(p)\n",
    "#         prompt_arry = p.splitlines()\n",
    "#         counter = 0\n",
    "#         unique_p = {} \n",
    "#         new_prompt_array = []\n",
    "#         for prompt in prompt_arry:\n",
    "#             # print(prompt)\n",
    "#             if prompt.startswith('[NC]'):\n",
    "#                 new_prompt_array.append(prompt)\n",
    "#             for name in list(match_set):\n",
    "#                 if f\"[{name}]\" in prompt:\n",
    "#                     if prompt not in unique_p:\n",
    "#                         new_prompt_array.append(prompt)\n",
    "#                         unique_p[prompt] = 1\n",
    "#                         counter += 1\n",
    "#                 if counter > 2:\n",
    "#                     story_lines_split.append(new_prompt_array)\n",
    "#                     new_prompt_array = []\n",
    "#                     unique_p = {}\n",
    "#                     counter = 0\n",
    "#                     break\n",
    "\n",
    "# [print('---:',p) for p in story_lines_split]         \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each story line will send to storydiffusion model to create a comic, count the characters in each line and add crespondant ref images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import re\n",
    "def count_character_names(character_names,line):\n",
    "    name_counter = {}\n",
    "    for name in character_names:\n",
    "        if f\"[{name}]\" in line:\n",
    "            if name in name_counter:\n",
    "                name_counter[name] += 1\n",
    "            else:\n",
    "                name_counter[name] = 1\n",
    "    return name_counter if name_counter else {'[NC]':1}\n",
    "\n",
    "\n",
    "#https://github.com/HVision-NKU/StoryDiffusion/blob/main/utils/gradio_utils.py\n",
    "# convert character list to dict\n",
    "def character_to_dict(general_prompt):\n",
    "    character_dict = {}    \n",
    "    generate_prompt_arr = general_prompt.splitlines()\n",
    "    character_index_dict = {}\n",
    "    invert_character_index_dict = {}\n",
    "    character_list = []\n",
    "    for ind,string in enumerate(generate_prompt_arr):\n",
    "        # 分割字符串寻找key和value\n",
    "        start = string.find('[')\n",
    "        end = string.find(']')\n",
    "        if start != -1 and end != -1:\n",
    "            key = string[start:end+1]\n",
    "            value = string[end+1:]\n",
    "            if \"#\" in value:\n",
    "                value =  value.rpartition('#')[0] \n",
    "            if key in character_dict:\n",
    "                raise Exception(\"duplicate character descirption: \" + key)\n",
    "            character_dict[key] = value\n",
    "            character_list.append(key)\n",
    "\n",
    "        \n",
    "    return character_dict \n",
    "\n",
    "def calc_id_length_prompt(general_prompt,prompts):\n",
    "    character_dict = character_to_dict(general_prompt)\n",
    "    replace_prompts = []\n",
    "    character_index_dict = {}\n",
    "    invert_character_index_dict = {}\n",
    "    for ind,prompt in enumerate(prompts):\n",
    "        for key in character_dict.keys():\n",
    "            if key in prompt:\n",
    "                if key not in character_index_dict:\n",
    "                    character_index_dict[key] = []\n",
    "                character_index_dict[key].append(ind)\n",
    "                if ind not in invert_character_index_dict:\n",
    "                    invert_character_index_dict[ind] = []\n",
    "                invert_character_index_dict[ind].append(key)\n",
    "        cur_prompt = prompt\n",
    "        if ind in invert_character_index_dict:\n",
    "            for key in invert_character_index_dict[ind]:\n",
    "                cur_prompt = cur_prompt.replace(key,character_dict[key])\n",
    "        replace_prompts.append(cur_prompt)\n",
    "    # print(replace_prompts)\n",
    "    ref_index_dict = {}\n",
    "    ref_totals = []\n",
    "    # print(character_index_dict)\n",
    "    id_length = 999\n",
    "    for character_key in character_index_dict.keys():\n",
    "        if character_key not in character_index_dict:\n",
    "            raise Exception(\"{} not have prompt description, please remove it\".format(character_key))\n",
    "        index_list = character_index_dict[character_key]\n",
    "        # print(invert_character_index_dict)\n",
    "        index_list = [index for index in index_list if len(invert_character_index_dict[index]) == 1]\n",
    "        # print(f'{character_key}:',index_list)\n",
    "        id_length = len(index_list) if len(index_list) < id_length else id_length\n",
    "        # if len(index_list) < id_length:\n",
    "        #     raise Exception(f\"{character_key} not have enough prompt description, need no less than {id_length}, but you give {len(index_list)}\")\n",
    "        ref_index_dict[character_key] = index_list[:id_length]\n",
    "        ref_totals = ref_totals + index_list[:id_length]\n",
    "    return id_length\n",
    "    \n",
    "def generate_img_dicts(characters):\n",
    "    character_names = [characters.main_character.name]\n",
    "    name_figure_map = {characters.main_character.name:characters.main_character.figure}\n",
    "    \n",
    "    # add supporting characters\n",
    "    for ch in characters.supporting_character:\n",
    "        character_names += [ch.name]\n",
    "        name_figure_map[ch.name] = ch.figure\n",
    "        \n",
    "\n",
    "    # print('name_figure_map:',name_figure_map)\n",
    "    imgs = {}\n",
    "    for key in list(name_figure_map.keys()):\n",
    "        if key not in imgs :\n",
    "            imgs[key] = Image2base64(f'./images/{key}.png')\n",
    "    return imgs\n",
    "\n",
    "    \n",
    "def prepare_storyd_prompts(story_lines,characters,img_dicts):\n",
    "    \"\"\"\n",
    "        prepare prompts for story diffusion model. \n",
    "        Use character's portrait as reference images to keep the consistance\n",
    "    \"\"\"\n",
    "    character_names = [characters.main_character.name]\n",
    "    name_figure_map = {characters.main_character.name:characters.main_character.figure}\n",
    "    \n",
    "    # add supporting characters\n",
    "    for ch in characters.supporting_character:\n",
    "        character_names += [ch.name]\n",
    "        name_figure_map[ch.name] = ch.figure\n",
    "        \n",
    "    # count character names in each line\n",
    "    name_counters = []\n",
    "    for line in story_lines:\n",
    "        name_counters.append(count_character_names(character_names,line))\n",
    "    # print('name_counters:',name_counters)\n",
    "    # generate prompt for each line\n",
    "    args = []\n",
    "    for name_counter,line in zip(name_counters,story_lines):\n",
    "        # id_length = len(list(name_counter.keys()))\n",
    "        ref_imgs = []\n",
    "        figures = []\n",
    "        for key in list(name_counter.keys()):\n",
    "            if key != '[NC]':\n",
    "                ref_imgs.append(img_dicts[key])\n",
    "                figures.append(f\"[{key}] {name_figure_map[key]} img\")\n",
    "            else:\n",
    "                figures.append(f\"[NC]\")\n",
    "                \n",
    "        prompt_array = line.split(\"\\n\")\n",
    "\n",
    "        # the model cannot generate one image with more than 2 character identities\n",
    "        prompt_array_new = []\n",
    "        pattern = r\"\\[(.*?)\\]\"\n",
    "        for text in prompt_array:\n",
    "            new_prompt = text\n",
    "            match = re.findall(pattern, text)\n",
    "            # check if the identity is in the first two of character dict\n",
    "            if match and match[0] != 'NC' and match[0] not in list(name_counter.keys())[:2]:\n",
    "                new_prompt = new_prompt.replace(f\"[{match[0]}]\",name_figure_map[key],1) \n",
    "                print(match[0], name_figure_map.keys(), name_counter.keys(),text,new_prompt)\n",
    "\n",
    "            match = re.findall(pattern, new_prompt)\n",
    "            if match and len(match) > 1:\n",
    "                for k in match[1:]:\n",
    "                    if k != 'NC': \n",
    "                        new_prompt = new_prompt.replace(f\"[{k}]\",name_figure_map[k]) \n",
    "\n",
    "            new_prompt = new_prompt if new_prompt.startswith('[NC]') else new_prompt\n",
    "\n",
    "            match = re.findall(pattern, new_prompt)\n",
    "            if not match:# if there is no bracket in the prompt line, it has to be add [NC]\n",
    "                new_prompt = '[NC]' + new_prompt \n",
    "            \n",
    "            prompt_array_new.append(new_prompt +'#' + text )# the text after # becomes caption \n",
    "\n",
    "        # calc id length\n",
    "        general_prompt = '\\n'.join(figures[:2]) #can only accept the first 2 figures currently, need to update in future              \n",
    "\n",
    "        id_length = 2\n",
    "        # add extral prompt for identity in case have enough prompt description for identity\n",
    "        prompt_array_new = [f.replace(' img','') for f in figures[:id_length]] + prompt_array_new\n",
    "\n",
    "        #re calc again after the prompt changed\n",
    "        id_length = calc_id_length_prompt(general_prompt, prompt_array_new)\n",
    "        id_length = 2 if id_length > 2 else id_length\n",
    "        # print(prompt_array_new)    \n",
    "        \n",
    "        # now the model can only support max 2 ref images in general prompt\n",
    "        # args.append({'prompt_array':prompt_array_new,'id_length':id_length,'ref_imgs':ref_imgs[:2],'general_prompt':general_prompt})\n",
    "        yield({'prompt_array':prompt_array_new,'id_length':id_length,'ref_imgs':ref_imgs[:2],'general_prompt':general_prompt})\n",
    "    # return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dicts = generate_img_dicts(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storyd_prompts = [r for r in prepare_storyd_prompts(all_story_lines,characters,img_dicts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ p['id_length'] for p in storyd_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ p['prompt_array'] for p in storyd_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lines[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use story diffusion model to refine the style of character images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using StoryDiffusion to generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'story-diffusion-inference-api-2024-05-17-14-07-20-411'\n",
    "stod_image_generator = StoryDiffusionGenerator(endpoint_name=endpoint,profile='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storyd_prompts[6]['prompt_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this step is very time consuming, while it takes 60s per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "# sytle = \"Comic book\"\n",
    "sytle = \"Japanese Anime\"\n",
    "comic_type = \"Four Pannel\"\n",
    "sd_type = \"Unstable\"\n",
    "\n",
    "for i,p in enumerate(storyd_prompts[start_index:]):\n",
    "    print(f\"line:{i},{p['prompt_array']}\")  \n",
    "    images = stod_image_generator.generate_images(general_prompt = p['general_prompt'],\n",
    "                                                    style=sytle,\n",
    "                                                    comic_type = comic_type,\n",
    "                                                    prompt_array='\\n'.join(p['prompt_array']),\n",
    "                                                    id_length= p['id_length'],\n",
    "                                                     sd_type = sd_type,\n",
    "                                                    ref_imgs=p['ref_imgs'],height=1024,width=1024)\n",
    "    # images = generate_images_api(\n",
    "    #     general_prompt = p['general_prompt'],\n",
    "    #                                                 style=sytle,\n",
    "    #                                                 comic_type = comic_type,\n",
    "    #                                                 sd_type = sd_type,\n",
    "    #                                                 prompt_array='\\n'.join(p['prompt_array']),\n",
    "    #                                                 id_length= p['id_length'],\n",
    "    #                                                 ref_imgs=p['ref_imgs'],height=768,width=768\n",
    "    # )\n",
    "    images_list.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_list)\n",
    "# images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img for imgs in images_list for img in imgs[::-1][-3:]] ##reverse the output order\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[display(img) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story.images = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_docx_few(characters,story,f'{story.page_title}_few_images_2.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use story diffusion model to refine the style of character images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_character_images(characters):\n",
    "    comic_type = \"Four Pannel\"\n",
    "    character_names = [characters.main_character.name]\n",
    "    name_figure_map = {characters.main_character.name:characters.main_character.figure}\n",
    "    \n",
    "    # add supporting characters\n",
    "    for ch in characters.supporting_character:\n",
    "        character_names += [ch.name]\n",
    "        name_figure_map[ch.name] = ch.figure\n",
    "    character_images = []\n",
    "    for p,name in zip(sd_prompts,character_names):\n",
    "        \n",
    "        prompt_array = f\"[{name}] {p.prompt}\"\n",
    "        general_prompt = f\"[{name}] \"+name_figure_map[name]+ ' img'\n",
    "        print(f\"general_prompt:{general_prompt}\\nprompt_array:{prompt_array}\")\n",
    "        ref_imgs = [img_dicts[name]]\n",
    "        images = stod_image_generator.generate_images(general_prompt = general_prompt,\n",
    "                                                        style=sytle,\n",
    "                                                        comic_type = comic_type,\n",
    "                                                        prompt_array=prompt_array,\n",
    "                                                        id_length=1,\n",
    "                                                        ref_imgs=ref_imgs,\n",
    "                                                        height=768,\n",
    "                                                        width=768)\n",
    "        # images = generate_images_api(general_prompt = general_prompt,\n",
    "        #                                                 style=sytle,\n",
    "        #                                                 comic_type = comic_type,\n",
    "        #                                                 prompt_array=prompt_array,\n",
    "        #                                                 id_length=1,\n",
    "        #                                                 ref_imgs=ref_imgs,\n",
    "        #                                                 height=768,\n",
    "        #                                                 width=768)\n",
    "        character_images.append(images)\n",
    "    save_all_images([ img[-1] for img in character_images],[name+'_refined' for name in character_names])\n",
    "    return character_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images = refine_character_images(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_as_docx_few(characters,story,f'{story.page_title}_few_images_2.docx',suffix='_refined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SRC_LANG = 'English'\n",
    "DIST_LANG = 'Chinese'\n",
    "\n",
    "\n",
    "translate_chapter_prompt = ChatPromptTemplate.from_messages( \n",
    " [    \n",
    "   (\n",
    "        \"system\",\n",
    "        role_config[\"translator\"]+fc_desc,\n",
    "        ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\", optional=True),  \n",
    " ])\n",
    "\n",
    "async def translate_chapter(chapter_obj: DetailChapter,source_lang:str,dist_lang:str):\n",
    "    name = \"translator\"\n",
    "    translate_chapter_chain = translate_chapter_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=DetailChapter)\n",
    "    request  = HumanMessage(content=f\"Here is the content to be translated:\\n{chapter_obj.json()}\",name=name)\n",
    "    translation = await retry_call(translate_chapter_chain,{\"source_lang\":source_lang,\"dist_lang\":dist_lang,\"messages\":[request],\"schema\":DetailChapter.schema_json()})\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chaps = [ chatper for chatper in  story.chapters]\n",
    "translate_all = RunnableLambda(translate_chapter).bind(source_lang=SRC_LANG,dist_lang=DIST_LANG)\n",
    "all_chaps = await translate_all.abatch(chaps)\n",
    "## merge all translated chapters\n",
    "story_trans = Story(page_title=story.page_title,chapters=all_chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def translate_character(characters_obj: Character,source_lang:str,dist_lang:str):\n",
    "    name = \"translator\"\n",
    "    translate_chapter_chain = translate_chapter_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=Character)\n",
    "    request  = HumanMessage(content=f\"Here is the content to be translated:\\n{characters_obj.json()}\",name=name)\n",
    "    translation = await retry_call(translate_chapter_chain,{\"source_lang\":source_lang,\"dist_lang\":dist_lang,\"messages\":[request],\"schema\":Character.schema_json()})\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "characters_trans = await translate_character(characters,SRC_LANG,DIST_LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_trans.images=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_as_docx_few(characters_trans,story_trans,f'{story.page_title}_few_images_{DIST_LANG}.docx',suffix='_refined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concate all workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def create_outline_node(state:AgentState):\n",
    "    steps = []\n",
    "    async for event in outline_workflow.astream(state):\n",
    "        steps.append(event)\n",
    "        for key, value in event.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            print(value)\n",
    "        print(\"\\n---\\n\")\n",
    "    env_var =  steps[-1]['generate_outline']['env_var']\n",
    "    return {'env_var':{**env_var}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_chapters_node(state:AgentState):\n",
    "    env_var = state['env_var']\n",
    "    outline = env_var['outline']\n",
    "    characters = env_var['characters']\n",
    "    write_all = RunnableLambda(write_all_chapters).bind(outline=outline,characters=characters)\n",
    "    chaps = [ chatper for chatper in  outline.chapters]\n",
    "    # write chatpers in parallel\n",
    "    all_steps =  await write_all.abatch(chaps)\n",
    "    \n",
    "    ## merge all English chapters\n",
    "    story = Story(page_title=outline.page_title,chapters=[s[0] for s in all_steps])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {'env_var':{**env_var,\"story\":story}}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SRC_LANG = 'English'\n",
    "DIST_LANG = 'Chinese'\n",
    "\n",
    "\n",
    "translate_chapter_prompt = ChatPromptTemplate.from_messages( \n",
    " [    \n",
    "   (\n",
    "        \"system\",\n",
    "        role_config[\"translator\"]+fc_desc,\n",
    "        ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\", optional=True),  \n",
    " ])\n",
    "\n",
    "async def translate_chapter(chapter_obj: DetailChapter,source_lang:str,dist_lang:str):\n",
    "    name = \"translator\"\n",
    "    translate_chapter_chain = translate_chapter_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=DetailChapter)\n",
    "    request  = HumanMessage(content=f\"Here is the content to be translated:\\n{chapter_obj.json()}\",name=name)\n",
    "    translation = await retry_call(translate_chapter_chain,{\"source_lang\":source_lang,\"dist_lang\":dist_lang,\"messages\":[request],\"schema\":DetailChapter.schema_json()})\n",
    "    return translation\n",
    "\n",
    "async def translate_character(characters_obj: Character,source_lang:str,dist_lang:str):\n",
    "    name = \"translator\"\n",
    "    translate_chapter_chain = translate_chapter_prompt | llm_sonnet | CustJsonOuputParser(verbose=True) |RunnableLambda(dict_to_obj).bind(target=Character)\n",
    "    request  = HumanMessage(content=f\"Here is the content to be translated:\\n{characters_obj.json()}\",name=name)\n",
    "    translation = await retry_call(translate_chapter_chain,{\"source_lang\":source_lang,\"dist_lang\":dist_lang,\"messages\":[request],\"schema\":Character.schema_json()})\n",
    "    return translation\n",
    "\n",
    "async def translate_node(state: AgentState):\n",
    "    env_var = state['env_var']\n",
    "    story = env_var['story']\n",
    "    assert not story == None\n",
    "    chaps = [ chatper for chatper in  story.chapters]\n",
    "    translate_all = RunnableLambda(translate_chapter).bind(source_lang=SRC_LANG,dist_lang=DIST_LANG)\n",
    "    all_chaps = await translate_all.abatch(chaps)\n",
    "    # merge all translated chapters\n",
    "    story_trans = Story(page_title=story.page_title,chapters=all_chaps)\n",
    "    # translate character description\n",
    "    characters = env_var['characters']\n",
    "    characters_trans = await translate_character(characters,SRC_LANG,DIST_LANG)\n",
    "    \n",
    "    return {'env_var':{**env_var,\"story_trans\":story_trans,\"characters_trans\":characters_trans}}\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "endpoint = 'story-diffusion-inference-api-2024-05-10-01-15-04-556'\n",
    "\n",
    "# from sagemaker endpoint\n",
    "stod_image_generator = StoryDiffusionGenerator(endpoint_name=endpoint,profile='4344')\n",
    "image_generator = ImageGenerator(profile='4344')\n",
    "\n",
    "gen_identity_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            role_config['art designer']+fc_desc,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\",optional=True),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_image_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            role_config['story illustrator']\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\",optional=True),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def generate_all_identities(characters,gen_identity_chain):\n",
    "    batch_inputs  = [{'messages':[HumanMessage(content=characters.main_character.appearance)],'schema':ImagePrompt.schema_json()}]\n",
    "    character_names = [characters.main_character.name]\n",
    "    for ch in characters.supporting_character:\n",
    "        batch_inputs += [{'messages':[HumanMessage(content=ch.appearance)],'schema':ImagePrompt.schema_json()}]\n",
    "        character_names += [ch.name]\n",
    "    \n",
    "    sd_prompts = gen_identity_chain.batch(batch_inputs)\n",
    "    \n",
    "    # use a self-hosted sdxl model to create portrait\n",
    "    # images = [generate_images_sdxl_api(prompt=sd_prompt.prompt) for sd_prompt in sd_prompts]\n",
    "    images = [image_generator.generate_image(prompt=sd_prompt.prompt) for sd_prompt in sd_prompts]\n",
    "    # print(images)\n",
    "    # save images in folder\n",
    "    # fname = [datetime.now().strftime(f\"%Y%m%d%H%M%S-{name}-{uuid.uuid4()}\") for name in character_names]\n",
    "    fname = save_all_images(images,character_names)\n",
    "    return fname\n",
    "        \n",
    "async def generate_portrait_node(state:AgentState):\n",
    "    env_var = state['env_var']\n",
    "    characters = env_var['characters']\n",
    "    gen_identity_chain = gen_identity_prompt | llm_sonnet | CustJsonOuputParser(verbose=False) |RunnableLambda(dict_to_obj).bind(target=ImagePrompt)    \n",
    "    fnames = generate_all_identities(characters,gen_identity_chain)\n",
    "    return {'env_var':{**env_var,\"portrait_files\":fnames}}\n",
    "\n",
    "async def generate_images_node(state:AgentState):\n",
    "    env_var = state['env_var']\n",
    "    story = env_var['story']\n",
    "    characters = env_var['characters']\n",
    "    gen_image_prompt_chain =  gen_image_prompt | llm_sonnet | TextOuputParser(verbose=False)\n",
    "    messages = []\n",
    "    for chapter in story.chapters:\n",
    "        messages += [{\"messages\":[HumanMessage(content='\\n'.join([ p.content for p in chapter.paragraphs]))]}] \n",
    "    all_story_lines = await gen_image_prompt_chain.abatch(messages)\n",
    "    \n",
    "    #construct prompt for storydiffusion\n",
    "    storyd_prompts,img_dicts = prepare_storyd_prompts(all_story_lines,characters)\n",
    "    \n",
    "\n",
    "    sytle = \"Comic book\"\n",
    "    comic_type = \"Four Pannel\"\n",
    "    images_list = []\n",
    "    for i,p in enumerate(storyd_prompts):\n",
    "        print(f\"line:{i},{p['prompt_array']}\")  \n",
    "        images = stod_image_generator.generate_images(general_prompt = p['general_prompt'],\n",
    "                                                        style=sytle,\n",
    "                                                        comic_type = comic_type,\n",
    "                                                        prompt_array='\\n'.join(p['prompt_array']),\n",
    "                                                        id_length=p['id_length'],\n",
    "                                                        ref_imgs=p['ref_imgs'],height=512,width=768)\n",
    "        images_list.append(images)\n",
    "    ##reverse the output order, only use the combined image\n",
    "    images = [img for imgs in images_list for img in imgs[::-1][-1:]] \n",
    "\n",
    "    # generate refined images for characters\n",
    "    character_images = refine_character_images(characters)\n",
    "\n",
    "    return {'env_var':{**env_var,\"images\":images,\"all_story_lines\":all_story_lines,\n",
    "                       \"images_list\":images_list,\"images\":images,\"character_images\":character_images}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_file_node(state:AgentState):\n",
    "    env_var = state['env_var']\n",
    "    story = env_var['story']\n",
    "    story_trans = env_var['story_trans']\n",
    "    characters = env_var['characters']\n",
    "    characters_trans = env_var['characters_trans']\n",
    "    images = env_var['images']\n",
    "    story.images = images\n",
    "    story_trans.images = images\n",
    "    save_as_docx_few(characters,story,f'{story.page_title}.docx',suffix='_refined')\n",
    "    save_as_docx_few(characters_trans,story_trans,f'{story_trans.page_title}_trans.docx',suffix='_refined')\n",
    "    return {'env_var':{**env_var,\"story\":story,\"story_trans\":story_trans}}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph = StateGraph(AgentState)\n",
    "build_graph.add_node(\"create_outline_node\",create_outline_node)\n",
    "build_graph.add_node(\"create_chapters_node\",create_chapters_node)\n",
    "build_graph.add_node(\"translate_node\",translate_node)\n",
    "build_graph.add_node(\"generate_portrait_node\",generate_portrait_node)\n",
    "build_graph.add_node(\"generate_images_node\",generate_images_node)\n",
    "build_graph.add_node(\"generate_file_node\",generate_file_node)\n",
    "build_graph.add_edge(\"create_outline_node\",\"create_chapters_node\")\n",
    "build_graph.add_edge(\"create_chapters_node\",\"generate_portrait_node\")\n",
    "build_graph.add_edge(\"generate_portrait_node\",\"generate_images_node\")\n",
    "build_graph.add_edge(\"generate_images_node\",\"translate_node\")\n",
    "build_graph.add_edge(\"translate_node\",\"generate_file_node\")\n",
    "build_graph.set_entry_point(\"create_outline_node\")\n",
    "build_graph.set_finish_point(\"generate_file_node\")\n",
    "workflow = build_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(workflow.get_graph().draw_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"续写一位霸道女总裁的故事。她从外交学院毕业之后，经过多年奋斗，终于进入了一家知名企业当副总裁，然而她对下属员工非常刻薄，她在个人抖音账号上发布了多条视频，包括“员工闹分手提离职我秒批”、“300封举报信撒满工位”等话题，这些视频内容引发了公众的热议和争议，终于被公司辞退。被公司辞退前她自己注册了一家公司。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=\"Continuing to write the story of a domineering female CEO. After graduating from the School of Foreign Affairs, she worked hard for many years and finally joined a well-known company as the vice president. However, she was very harsh towards her subordinates, which led to her being publicly posted online and reported, and finally dismissed by the company. Before being dismissed by the company, she registered a company herself.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "init_state = {\n",
    "    \"env_var\":{},\n",
    "    \"messages\":[HumanMessage(content=f\"Here is the topic:{topic}\")]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async for event in workflow.astream(input=init_state):\n",
    "    steps.append(event)\n",
    "    for key, value in event.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inter_state = AgentState(steps[-1]['generate_images_node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translate_state = await translate_node(inter_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "await generate_file_node(translate_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
