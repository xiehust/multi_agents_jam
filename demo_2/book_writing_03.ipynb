{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a262470d-15cb-4a69-8059-8d8baefcabad",
   "metadata": {},
   "source": [
    "# Build an autonomous multi-agents workflow to write picture book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17d3e1-7dd4-4e38-979b-0e7d9e5487db",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "- **Goal**: Write a outline for a story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c2834-d7b8-4600-8e1e-3cfdf489a5ee",
   "metadata": {},
   "source": [
    "### 1. Install dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682675cb-d9a0-4947-8ad4-4511e77fb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain_community==0.0.32 langgraph==0.0.51 langchain-aws==0.1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d541e-6cb4-48c6-8d4e-53acc0cb36a4",
   "metadata": {},
   "source": [
    "### 2. Some Utils functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095aa5c8-d5ea-441c-8609-10c48c93ddf6",
   "metadata": {},
   "source": [
    "#### 2.1 Structrued Output parser\n",
    "- In our case, we need to parse the LLM output to a pydantic object, so will define Structrued Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d52631e-9eb7-4eab-958a-ae9441b2589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from json import JSONDecodeError\n",
    "def dict_to_obj(json_str:dict, target:object):\n",
    "    return target.parse_obj(json_str)\n",
    "\n",
    "\n",
    "class CustJsonOuputParser(BaseOutputParser[str]): \n",
    "    verbose :bool = Field( default=True)\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        if self.verbose:\n",
    "            print(text)\n",
    "        pattern = r\"<answer>(.*?)</answer>\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "        else:\n",
    "            return {'answer':\"no\"}    \n",
    "        new_dict = json.loads(text.replace('\\n','  '))\n",
    "        \n",
    "        return new_dict\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "class TextOuputParser(BaseOutputParser[str]): \n",
    "    verbose :bool = Field( default=True)\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        if self.verbose:\n",
    "            print(text)\n",
    "        pattern = r\"<answer>(.*?)</answer>\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            return text.strip()\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"TextOuputParser\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032eff3-205e-489a-9793-564257d15a80",
   "metadata": {},
   "source": [
    "#### 2.2 LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d649fd2-d40d-479f-bfbc-b5558744b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_sonnet = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.8,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.9,\n",
    "                                \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                #   callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                )\n",
    "\n",
    "llm_haiku = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.8,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.9,\n",
    "                                \"stop_sequences\":['</invoke>','</error>']\n",
    "                               },\n",
    "                  streaming=True,\n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a13a3-91ed-490c-9487-d88d3d74d226",
   "metadata": {},
   "source": [
    "#### 2.3 Image Generation model invoke code\n",
    "- Bedrock SD model invoke, here we use Bedrock SD to generate portrait of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8c1402-7655-49b6-83b6-ed0d99478c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from botocore.exceptions import ClientError\n",
    "from enum import Enum\n",
    "from io import BytesIO\n",
    "\n",
    "# profile='default'\n",
    "profile=''\n",
    "\n",
    "class StyleEnum(Enum):\n",
    "    Photographic = \"photographic\"\n",
    "    Tile_texture = \"tile-texture\"\n",
    "    Digital_art = \"digital-art\"\n",
    "    Origami = \"origami\"\n",
    "    Modeling_compound = \"modeling-compound\"\n",
    "    Anime = \"anime\"\n",
    "    Cinematic = \"cinematic\"\n",
    "    Model_3D = \"3d-model\"\n",
    "    Comicbook = \"comic-book\"\n",
    "    Enhance = \"enhance\"\n",
    "    \n",
    "class ImageError(Exception):\n",
    "    \"Custom exception for errors returned by SDXL\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "class ImageGenerator(BaseModel):\n",
    "    model_id: str = Field(default=\"stability.stable-diffusion-xl-v1\")\n",
    "    profile:str\n",
    "    cfg_scale: int = Field( default=7)\n",
    "    steps:int = Field( default=50)\n",
    "    samples:int = Field( default=1)\n",
    "    \n",
    "    def _generate(self,model_id, body):\n",
    "        \"\"\"\n",
    "        Generate an image using SDXL 1.0 on demand.\n",
    "        Args:\n",
    "            model_id (str): The model ID to use.\n",
    "            body (str) : The request body to use.\n",
    "        Returns:\n",
    "            image_bytes (bytes): The image generated by the model.\n",
    "        \"\"\"\n",
    "\n",
    "        # logger.info(\"Generating image with SDXL model %s\", model_id)\n",
    "\n",
    "        session = boto3.Session()\n",
    "        # session = boto3.Session(profile_name=self.profile)\n",
    "        #get bedrock service \n",
    "        bedrock = session.client(service_name='bedrock-runtime')\n",
    "    \n",
    "        accept = \"application/json\"\n",
    "        content_type = \"application/json\"\n",
    "\n",
    "        response = bedrock.invoke_model(\n",
    "            body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "        base64_image = response_body.get(\"artifacts\")[0].get(\"base64\")\n",
    "        base64_bytes = base64_image.encode('ascii')\n",
    "        image_bytes = base64.b64decode(base64_bytes)\n",
    "\n",
    "        finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\")\n",
    "\n",
    "        if finish_reason == 'ERROR' or finish_reason == 'CONTENT_FILTERED':\n",
    "            raise ImageError(f\"Image generation error. Error code is {finish_reason}\")\n",
    "\n",
    "\n",
    "        # logger.info(\"Successfully generated image withvthe SDXL 1.0 model %s\", model_id)\n",
    "\n",
    "        return image_bytes\n",
    "\n",
    "    def generate_image( self,prompt,seed=0,style_preset=StyleEnum.Photographic.value):\n",
    "        if self.model_id.startswith('stability'):\n",
    "            body=json.dumps({\n",
    "                \"text_prompts\": [\n",
    "                {\n",
    "                \"text\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"cfg_scale\": self.cfg_scale,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": self.steps,\n",
    "              \"height\": 768,\n",
    "            \"width\": 768,\n",
    "            \"samples\" : self.samples,\n",
    "            \"style_preset\" : style_preset\n",
    "            })\n",
    "        elif self.model_id.startswith('amazon'):\n",
    "            body = json.dumps({\n",
    "            \"taskType\": \"TEXT_IMAGE\",\n",
    "            \"textToImageParams\": {\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"height\": 768,\n",
    "                \"width\": 768,\n",
    "                \"cfgScale\": self.cfg_scale,\n",
    "                \"seed\": seed\n",
    "            }\n",
    "            })\n",
    "        print(body)\n",
    "        image= None\n",
    "        try:\n",
    "            image_bytes=self._generate(model_id = self.model_id,\n",
    "                                    body = body)\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        except ClientError as err:\n",
    "            message=err.response[\"Error\"][\"Message\"]\n",
    "            # logger.error(\"A client error occurred: %s\", message)\n",
    "            print(\"A client error occured: \" +format(message))\n",
    "        except ImageError as err:\n",
    "            print(err)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "        finally:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e71643-af06-43df-b81b-e6cf58af152d",
   "metadata": {},
   "source": [
    "- Sagemaker model invoke. Here we use StoryDiffusion to generate consecutive images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a9264-8900-43fc-a386-06919a083268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from typing import Any, List\n",
    "import json\n",
    "import io\n",
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "import time\n",
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "\n",
    "def base64_to_image(base64_string):\n",
    "    image_bytes = base64.b64decode(base64_string)\n",
    "    image_buffer = BytesIO(image_bytes)\n",
    "    image = Image.open(image_buffer)\n",
    "    return image\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "\n",
    "class StoryDiffusionGenerator():\n",
    "    \"\"\" API schema\n",
    "    class APIRequest(BaseModel):\n",
    "        sd_type: Literal['RealVision','SDXL','Unstable'] = Field(default='SDXL')\n",
    "        modeltype : Literal[\"Only Using Textual Description\",\"Using Ref Images\"] = Field(default=\"Only Using Textual Description\")\n",
    "        files: Any = Field(default=None)\n",
    "        num_steps : int = Field(default=50)\n",
    "        style : Literal[\"Japanese Anime\",\"(No style)\",\"Cinematic\",\"Disney Charactor\",\"Photographic\",\"Comic book\",\"Line art\"] = Field(default=\"Comic book\")\n",
    "        Ip_Adapter_Strength : float = Field(default=0.5, descrition=\"The strength of the IP adapter. The value ranges from 0 to 1. The larger the value, the stronger the IP adapter.\")\n",
    "        style_strength_ratio : int = Field(default=20 ,descrition=\"Style strength of Ref Image (%)\")\n",
    "        guidance_scale: float = Field(default=5.0)\n",
    "        seed_: int = Field(default=0)\n",
    "        sa32_:float = Field(default=0.5)\n",
    "        sa64_:float = Field(default=0.5)\n",
    "        id_length_ : int = Field(default=2,descrition=\"Number of id images in total images\")\n",
    "        general_prompt : str = Field(...,descrition=\"Textual Description for Character\")\n",
    "        negative_prompt : str =  Field(default=\"naked, deformed, bad anatomy, disfigured, poorly drawn face, mutation, extra limb, ugly, disgusting, poorly drawn hands, missing limb, floating limbs, disconnected limbs, blurry, watermarks, oversaturated, distorted hands, amputation\")\n",
    "        prompt_array: str =  Field(...,descrition=\"Comic Description (each line corresponds to a frame)\")\n",
    "        G_height: int = Field(default=512)\n",
    "        G_width: int = Field(default=512)\n",
    "        comic_type : Literal['No typesetting (default)','Four Pannel','Classic Comic Style'] = Field(default='Classic Comic Style')\n",
    "        font_choice :str = Field(default='Inkfree.ttf')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,endpoint_name,profile):\n",
    "        endpoint_name = endpoint_name\n",
    "        # boto_session= boto3.Session(profile_name=profile)\n",
    "        boto_session= boto3.Session()\n",
    "        self.s3_resource = boto_session.resource(\"s3\")\n",
    "        sagemaker_session = sagemaker.Session(boto_session = boto_session)\n",
    "        bucket  = sagemaker_session.default_bucket()\n",
    "        output_path  = \"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"story-diffusion\")\n",
    "        input_path :str = \"s3://{0}/{1}/asyncinvoke/in/\".format(bucket, \"story-diffusion\")\n",
    "        \n",
    "        predictor_ = Predictor(\n",
    "            endpoint_name=endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            model_data_input_path=input_path,\n",
    "            model_data_output_path=output_path,\n",
    "        )\n",
    "        predictor_.serializer = JSONSerializer()\n",
    "        predictor_.deserializer = JSONDeserializer()\n",
    "        self.config = WaiterConfig(\n",
    "            max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    "        )\n",
    "        self.predictor_async = AsyncPredictor(\n",
    "                predictor_,\n",
    "                name='story-diffusion'\n",
    "        )\n",
    "\n",
    "    def generate_images(self,general_prompt:str,prompt_array:str,id_length:int=2, ref_imgs: List[Any]= [],comic_type:str='Classic Comic Style', style:str = 'Japanese Anime',sd_type:str=\"Unstable\", height:int = 512, width :int = 768) -> list:\n",
    "        data = { \"general_prompt\": general_prompt,\n",
    "                        \"prompt_array\" : prompt_array,\n",
    "                        \"style\" : style,\n",
    "                        \"G_height\" : height,\n",
    "                        \"G_width\" : width,\n",
    "                        \"comic_type\" : comic_type,\n",
    "                       \"files\":ref_imgs,\n",
    "                        \"id_length_\":id_length,\n",
    "                        \"sd_type\":sd_type,\n",
    "                }\n",
    "        if not ref_imgs:\n",
    "            del data['files']\n",
    "        # print(data)\n",
    "        prediction = self.predictor_async.predict_async(data)\n",
    "        print(f\"Response output path: {prediction.output_path}\")\n",
    "        start = time.time()\n",
    "        prediction.get_result(self.config)\n",
    "        print(f\"Time taken: {time.time() - start}s\")\n",
    "        \n",
    "        output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "        output_obj = self.s3_resource.Object(output_bucket, output_key)\n",
    "        body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "        \n",
    "        respobj = json.loads(body)\n",
    "        images = []\n",
    "        for img in respobj['images_base64']:\n",
    "            images.append(base64_to_image(img))\n",
    "            \n",
    "        # images =get_async_result(prediction)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28feffd4-a481-4154-94fe-81df648cf157",
   "metadata": {},
   "source": [
    "- generate image from model in ec2 server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac93cb8-130b-4c7b-9336-acbc4afc8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
